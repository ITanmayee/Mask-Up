{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Trainer_Mask.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/ITanmayee/Mask-Up/blob/main/Trainer_Mask.ipynb",
      "authorship_tag": "ABX9TyNiZyBYOCPM6iXmvq29LzRA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ITanmayee/Mask-Up/blob/main/Trainer_Mask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiEW-eltErLM"
      },
      "source": [
        "import os\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgePePXJ8qYU"
      },
      "source": [
        "DIRECTORY = r\"/content/drive/MyDrive/dataset\"\n",
        "CATEGORIES = [\"with_mask\", \"without_mask\"]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Lu4KDpIET4h",
        "outputId": "d2c92c91-08ee-431c-8b2f-c7a34d635e4a"
      },
      "source": [
        "data = []\n",
        "labels = []\n",
        "\n",
        "for category in CATEGORIES:\n",
        "    path = os.path.join(DIRECTORY, category)\n",
        "    for img in os.listdir(path):\n",
        "    \timg_path = os.path.join(path, img)\n",
        "    \timage = load_img(img_path, target_size=(224, 224))\n",
        "    \timage = img_to_array(image)\n",
        "    \timage = preprocess_input(image)\n",
        "\n",
        "    \tdata.append(image)\n",
        "    \tlabels.append(category)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnKOBzprIq-U"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import numpy as np"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STEbORUKIZWa"
      },
      "source": [
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "labels = to_categorical(labels)\n",
        "\n",
        "data = np.array(data, dtype=\"float32\")\n",
        "labels = np.array(labels)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAEjIz3rIyjL"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,test_size=0.20, stratify=labels, random_state=42)\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DG013GAbHlB1",
        "outputId": "9ebbc16f-2b1a-44d8-92a1-72ce5c6ae234",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Inputno bro we\n",
        "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
        "\tinput_tensor=Input(shape=(224, 224, 3)))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPXGkT68IAHq"
      },
      "source": [
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(128, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(2, activation=\"softmax\")(headModel)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVVqRhIHI0vS"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)"
      ],
      "execution_count": 37,
      "outputs": []
    }
  ]
}